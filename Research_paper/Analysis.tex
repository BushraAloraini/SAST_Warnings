


\subsection{Analysis}
After the data collection phase, we got \textbf{n} number of hit lists in each repository based on the number of checkpoints for that repository. To answer each of our research questions, we needed to identify which vulnerability warning is false positive and which is true positive. Based on that information, we could get a list of true positive warnings that helps us to further answer RQ2 and RQ3. So, our method depend on analyzing vulnerabilities though history and based on that we could decide whether a given warnings is false or true positive. We have the following simple assumptions to decide if a warning is true or false positive:
\begin{enumerate}
\item False positive: we consider any warning that reappeared until the last updated check point as false positive. 
\item True positive: any vulnerability otherwise is considered to be true positive as it was removed in later versions. 
\end{enumerate}
\subsubsection{\textbf{Analysis Phases}}
Our data could be challenging, as we first need to know whether a vulnerability that appeared in checkpoint \textit{x} is the same exact one that appeared in checkpoint \textit{x+1}, etc. Some vulnerabilities could appear in one checkpoint and have the same exact signature but with different line number. Hence, with our analysis through the history we needed to know which one in checkpoint \textit{x} matches which one in checkpoint\textit{x+1}.
However, there could be a simpler situation where a vulnerability could reaper with the same whole exact signature. Thus, we wanted to do the analysis by initially excluding likely false positive warnings. So, we achieved the analysis in multiple phases. In the first phase,  we copied the hit list files that were generated initially to  edit them based on our finding on that phase. Then, we fed that particular phase files to the next phase to carry out 
the analysis on the next phase, and so on. All phases are illustrated in the following section:
\begin{itemize}

\item{\textbf{Phase one: exclude all likely false positive warnings}} In the first phase, all vulnerability warnings with the same exact signature (including the line number); that appeared at any checkpoint and still reappear continuously until the last checkpoint are considered to be false positives. We emphasis on the continuity of the warnings, as one warning that appears in  checkpoint \textit{x} then removed in checkpoint\textit{x+1}, but reappeared in checkpoint \textit{x+2} will not considered the same. In this situation we consider the warnings that appeared in checkpoint \textit{x} and checkpoint\textit{x+2} to be two different vulnerabilities. We did the analysis by examining the hit list of the last checkpoint with all previous checkpoints. In our analysis, we considered hit\_list\_1 to be the last updated one and hit\_list\_n to be the oldest hit list.
Hence, in this phase we fed copies of \textbf{n} hit list files of a repository that named as phase1\_hit\_list\_1 ... n to the analysis. Then, we just examine warnings that appeared in phase1\_hit\_list\_1 with all other previous n hit list files. When we found a warning that appeared exactly at all previous checkpoints continuously we marked it as false positive. For example, if we have 8 checkpoints, and thus we have files to be analyzed named as phase1\_hit\_list\_1 ... 8.  In this case we examine phase1\_hit\_list\_1 and all previous files. If we find for instance that  phase1\_hit\_list\_2 and phase1\_hit\_list\_3 have the same exact line of warnings we mark it as false positive. So we delete that line of warnings from phase1\_hit\_list\_1,2,3 and add that warning to a created \texttt{false\_positive} list. By doing so, we could feed phase1\_hit\_list1...n to the next phase and avoid analyzing the same warnings multiple times. Also, we could guarantee the uniqueness of the warning by counting all same false positive as one when store it in the false positive list. 


\item{\textbf{Phase two: exclude continuous false positive warnings}} in this phase we fed the phase1\_hit\_list1... n files that were generated in the previous phase into this phase and copied them to be named as  phase2\_hit\_list1... n. This will allow us to keep track of our data and keep as much as possible of information about the analysis. So, after excluding all false positives that have the same exact signature including the line number, we had to look for false positives that were still reintroduced in later versions until the last updated checkpoint. However this time we had to track potentially similar warnings but with different line numbers. First, we created a list of all possible exact warnings with different line number that appeared in the last updated checkpoint and among all checkpoints. So each warning is stored with all possible line numbers in other checkpoints. Note that some warnings could appears in checkpoint \textit{x} but in checkpoint \textit{x+1} there are two similar warnings both with different line number that the warning in checkpoint \textit{x}. So, we examined all warnings that appeared in phase2\_hit\_list1 and keep track of all previous and similar vulnerabilities in preceding checkpoints.  Then, we applied the \textbf{line\_match algorithm} which will be described in Section \ref{alg} to determine which vulnerabilities that match the last updated vulnerability. After that a list of all matching vulnerabilities in preceding checkpoints was created. So before we decide that a given vulnerability is false positive, we check to see whether the list that we got contain a contentious checkpoints. If that is the case, the vulnerability is considered as false positive, otherwise is left untouched. All false positives are deleted from phase2\_hit\_list\_1 and other hit lists that include the vulnerability, and added to the \texttt{false\_positive} list.


\item{\textbf{Phase three: exclude continuous true positive warnings}}
Similarly to previous phases, in this phase we fed the phase2\_hit\_list1... n files that were generated in the previous phase into this phase and copied them to be named as phase3\_hit\_list1... n. While, in all previous phases we only considered warnings that appeared in the last updated checkpoint and trace all similar vulnerabilities in preceding checkpoints, we considered all warnings that appeared at any checkpoint in this phase. That is because in the previous phases we were interested in all false positives, which imply that a vulnerability should appear in the last updated checkpoint to be considered false positive. However, in this phase we are interested in true positive that could appear any time. Actually in this phase phase2\_hit\_list1 should be empty as we had to remove all false positive warnings, and all we did in the previous phases is to remove other similar vulnerabilities from other checkpoints. In this phase, we loop through all checkpoints one by one and examined all warnings in that specific checkpoint with all previous checkpoints. We Started with phase3\_hit\_list\_2, because phase3\_hit\_list\_1 is already empty. Then when looped through all \textbf{n-2} previous checkpoints, then we examined phase3\_hit\_list\_3 with all previous checkpoints, and so on. With each loop, we created a list of potential  similar vulnerabilities in different checkpoints. Also, in this phase we used \textbf{line\_match algorithm}  to determine whether the given list of similar vulnerabilities with different line number in different checkpoints are indeed the same. The algorithm will produce a list of vulnerabilities that are the same with the matching checkpoint. So, similarly to phase 2 we check the continuity of the checkpoints. If a given list contains similar and continuous true positive warnings, the warnings are removed from the phase3\_hit\_list files and added to a created \texttt{true\_positive} list. Also, we extract the age of each true positive vulnerability and added to the \texttt{true\_positive} list. So, the \texttt{true\_positive} list contains the true positive warnings and the vulnerability age.


\item{\textbf{Phase four: exclude all remaining true positive warnings}}
Again, in this phase we fed the phase3\_hit\_list1... n files that were generated in the previous phase into this phase and copied them to be named as phase4\_hit\_list1... n. So, as we removed all false positive warnings and all continuous true positive warnings, the copied files will only include vulnerabilities that are unique and do not reintroduced in all other files ( and potentially all warnings that our algorithm failed to determine their continuity Section \ref{ttv}).  So, we looped through all phase4\_hit\_list files and stored the remaining warnings as true positives in the \texttt{true\_positive} list. When we added those vulnerabilities to the \texttt{true\_positive} list, we marked them as phase4 warnings and we did the same thing with phase3 warnings as well. This could help us with the further analyzing our algorithm.
\end{itemize}

\subsubsection{\textbf{line\_match Algorithm}\label{alg}}
Our problem requires to determine whether two  lines of code  in two different source code file versions are indeed the same. We first tried to use possible available git tools to do so. First, we thought of using \texttt{git blame}, however it does not really help with our problem as it does not tell if a given line of code is indeed the same in different versions of files. Also, \texttt{git diff} provide a general solution that only gives the number of added or deleted lines in examined files. Thus, we had to create our own solution which uses \texttt{git diff} that provides a partial solution. Therefore, we proposed this algorithm to enable us to trace and decide whether a given bug warning that appears in different versions of source code files is indeed the same. This algorithm could be also applied to any other problem where one needs to trace a line of code in different version of source code files. 

The main idea here is simply when  comparing two versions of files to trace a specific line, we want to to calculate the number of added and deleted lines up to that line number. To clarify this, let \texttt{a} be the first file to be compared and \texttt{b} be the second file to be fed to \texttt{git diff}.  Let \textit{l\_a} be the line of code that include the warning context in file \texttt{a} that is similar to \textit{l\_b} which is the line of code that include the warning context in file \texttt{b}. Also, let \textit{ln\_a} be the line number of \textit{l\_a} and  \textit{ln\_b} be the line number of \textit{l\_b}. 

%\begin{equation}
%\textit{l\_a} = \textit{l\_b} 
%\end{equation}
%\begin{equation}
%\textit{ln\_a} \neq \textit{ln\_b}
%\end{equation}

 
So, we want to see if these two lines  have different line numbers  due to file alteration. So by retrieving the original line number for both files and match each line number in file \textit{a} to the matching line number in  file \textit{b}. Then, when we counted the the number of addition and deletion until the line \textit{ln\_a}, so we could decide for sure if \textit{ln\_a} equal \textit{ln\_b}. However, how could we get this kind of information. Let first explain how \texttt{git diff} command output helped us. When issuing \texttt{git diff  commit\_a commit\_b filename}, the output gives a number of hunks that show one area where the files differ as follow:

@@ from-file-line-numbers to-file-line-numbers @@
The line numbers of the hunk usually look like ``start,count'' \texttt{start} refers to the line number that has changed, and \texttt{count} refers to how long the hunk is. When we specify \textbf{-U number}  flag (where \texttt{number} could include the maximum line number we could get), we could retrieve one hunk that includes the whole file from the beginning to the end.  Also, \texttt{git diff} prints \textbf{- , +} to indicate the addition or deletion of lines. So, by utilizing this information, we could retrieve line numbers in file \texttt{a} to match line numbers in file \texttt{b} based on the given hunk. Then, We could count the number of addition or deletion before and after \textit{ln\_a}.

%After that, we calculate the value \textit{alter\_diff} which refers to the difference between the addition and the deletion before \textit{ln\_a} as follow: 

% \begin{equation}
%\textit{alter\_diff} = \textit{num\_addition}  - \textit{num\_deletion} 
%\end{equation}

%Then, we calculated the difference between \textit{ln\_a} and \textit{ln\_b}

%\begin{equation}
%\textit{line\_diff} = \textit{ln\_b} - %\textit{ln\_a}
%\end{equation}

%If we find that \textit{line\_diff} = \textit{alter\_diff} this will indicate that the two lines are indeed the same.
Algorithm \ref{match}  shows the whole method.

 

\begin{algorithm}
 \KwData{ln\_b ,  ln\_a , filename, commit\_a , and commit\_b}
 \KwResult{ answer is ln\_b  equal  ln\_a} 

  git diff  -U max\_line\_num  commit\_a commit\_b  --  filename, then; 
  
  Using diff hunk, retrieve and match line numbers for files a and b; 
 
 Print all + and - marks and send the output to result\_file; 

num\_addition=0;

num\_deletion=0;

\While{reading result\_file}{
\While{ $line\_number <  $ln\_a}{
  read line\;
  \If{line \textbf{contains} + at the beginning}{
   num\_addition =  num\_addition + 1;  
   }
   
  
   \If{line \textbf{contains} - at the beginning}{
         num\_deletion =  num\_deletion + 1;    }
 
 }
 alter\_diff  =  num\_addition   -  num\_deletion;
 
 line\_diff  =  ln\_b  -  ln\_a;
 
 

\eIf{$alter\_diff =  $line\_diff }{
       $l\_a =  $l\_b;
   }
     { 
      $l\_a \neq $l\_b;
     }
 }
 
 
 
 \caption{ line\_match algorithm to determine whether two similar lines in two different versions of files are indeed the same}
 \label {match}
\end{algorithm}


To determine the altered lines of code, we use the algorithm to determine weather a line of code is related to addition and deletion in the other file version in the same hunk (in the same context by measure above and below code). Then, we use edit distance method to determine if the line is modified or not.